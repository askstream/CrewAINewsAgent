## Архитектура News Agent

News Agent использует модульную архитектуру: каждый этап обработки новостей (сбор, дедупликация, классификация, саммари, embeddings и поиск) реализован отдельными модулями в `agents/`, а оркестрация выполняется через Flask‑приложение (`app.py`) и/или CLI‑режим (`cmd_mode/`).

---

## Общий поток обработки

Обработка новостей выполняется в несколько этапов.

### Этап 1: Сбор новостей
- Парсинг каждого указанного RSS‑канала.
- Извлечение:
  - заголовка (`title`);
  - содержания (`summary` / `description`);
  - ссылки на полную статью (`link`);
  - даты публикации (`published_at`);
  - названия источника (`source`).
- Генерация `content_hash` для быстрой проверки дубликатов.
- Проверка существования статьи в БД (по ссылке и истории поиска).
- Сохранение новых статей в таблицу `news_articles`.

### Этап 2: Дедупликация
- Получение всех необработанных статей текущего запроса.
- Двухуровневая проверка:
  - точные дубликаты — по `content_hash`;
  - похожие статьи — по текстовой схожести (заголовок + содержание, алгоритм `SequenceMatcher`).
- Определение оригинальной статьи (как правило, с более ранней датой публикации).
- Пометка дубликатов в БД: `is_duplicate = True`, `duplicate_of = <id оригинала>`.

### Этап 3: Классификация релевантности
- Для каждой уникальной статьи:
  - формируется промпт на основе текста статьи и `selection_criteria`;
  - отправляется запрос к LLM API (через прямой HTTP или LangChain в зависимости от настроек);
  - ожидается JSON‑ответ с оценкой релевантности;
  - при ошибке LLM вызывается fallback‑классификация по ключевым словам.
- В `news_articles` сохраняются:
  - `relevance_score` (0.0–1.0);
  - `is_relevant` (флаг по порогу, например `>= 0.6`);
  - `classification_reason` (объяснение/причина решения).

### Этап 4: Генерация саммари (опционально)
- Загружаются релевантные статьи (`is_relevant = True`, `is_duplicate = False`) текущего запроса.
- Для каждой статьи:
  - очищается HTML (регулярные выражения, декодирование HTML‑сущностей);
  - подготавливается текст ограниченной длины;
  - формируется промпт с инструкцией «краткое саммари 2–3 предложения».
- Саммари генерируется:
  - либо через прямой HTTP‑запрос к LLM;
  - либо через LangChain (fallback);
  - либо простым `simple_summary` (первые предложения текста) при ошибках API.
- Результат сохраняется в поле `summary` таблицы `news_articles`.

### Этап 5: Генерация embeddings (опционально)
- Собирается список ID уникальных статей текущего запроса.
- Для каждой статьи по ID:
  - статья повторно загружается из свежей сессии БД;
  - извлекаются `title` и `content` и приводятся к строкам;
  - текст очищается от HTML, при необходимости укорачивается до лимита.
- Отправляется запрос к Embeddings API (OpenAI или совместимый):
  - по умолчанию `text-embedding-3-small` (размер вектора 1536);
  - для Ollama — например, `snowflake-arctic-embed2`.
- Полученный вектор сохраняется в JSON‑поле `embedding` в `news_articles`.
- Embeddings используются для семантического поиска.

---

## Веб‑интерфейс и API (`app.py`)

### Вкладка «Поиск»
- Форма с:
  - списком RSS‑каналов;
  - текстовым критерием отбора (`selection_criteria`);
  - параметрами LLM и дедупликации (модель, температура, порог схожести).
- Блок «Текущие настройки системы»:
  - подгружается из конфигурации/БД;
  - показывает текущие значения модели, температуры, порога схожести и API endpoint.
- Прогресс‑бар по этапам:
  1. Сбор новостей.
  2. Дедупликация.
  3. Классификация (включая саммари и embeddings).
- Обновление статуса:
  - с периодическим опросом API;
  - с цветовой индикацией (ожидание / выполняется / завершено / ошибка).

### Таблица новостей
- Отображаются только уникальные статьи текущего запроса.
- Основные поля:
  - ID, источник, дата, заголовок, релевантность.
- Для каждой статьи:
  - саммари (для релевантных статей);
  - полное содержание с HTML‑разметкой (разворачиваемый блок);
  - причина классификации.
- Визуальные элементы:
  - релевантные статьи подсвечиваются зелёным фоном;
  - строки группируются по статье, статистика отображается вверху.

### Вкладка «История запросов»
- Таблица `search_history` с пагинацией (например, по 5 записей).
- При выборе записи:
  - отображаются все параметры запроса;
  - выводится статистика (количество статей, релевантных, дубликатов и т.п.);
  - подгружается список статей, связанных с `search_history_id`.
- Управление:
  - удаление отдельного запроса (с каскадным удалением статей);
  - полная очистка БД.

### Вкладка «Системные настройки»
- Настройки семантического поиска:
  - адаптивные пороги схожести для запросов разной длины (1 слово, 2 слова, 3 слова, 4–5, 6+);
  - параметры keyword‑matching (минимальный процент совпадений, вес буста, минимальный итоговый score).
- Все настройки хранятся в таблице `system_settings` и могут меняться без рестарта.
- Есть кнопка «Инициализировать по умолчанию» для сброса настроек.

---

## Модули `agents/`

### `agents/rss_collector.py`
- `collect_rss_news()` – парсинг RSS‑каналов через `feedparser`.
- `get_content_hash()` – генерация SHA256‑хеша по содержимому для быстрой проверки дубликатов.

### `agents/deduplicator.py`
- `find_duplicates()` – поиск дубликатов и похожих статей.
- `calculate_similarity()` – вычисление текстовой схожести (заголовок/контент, `SequenceMatcher`).
- `mark_duplicates()` – пометка дубликатов в БД (`is_duplicate`, `duplicate_of`).

### `agents/classifier.py`
- `classify_article_relevance()` – основная точка входа для классификации.
- `classify_with_direct_api()` – прямой HTTP‑запрос к LLM‑провайдеру.
- `simple_classification()` – fallback‑алгоритм по ключевым словам.
- `classify_articles()` / `classify_articles_with_settings()` – пакетная обработка статей с учётом настроек.

### `agents/llm_utils.py`
- `create_llm()` / `create_llm_with_settings()` – создание клиента LLM c корректной обработкой `OPENAI_API_BASE`.
- Поддержка:
  - стандартного OpenAI API;
  - прокси‑провайдеров;
  - локального Ollama‑endpoint.

### `agents/summarizer.py`
- `generate_summary()` – единая точка входа для генерации саммари:
  1. попытка прямого HTTP‑запроса к LLM;
  2. fallback через LangChain;
  3. fallback на `generate_simple_summary()`.
- `generate_summary_with_direct_api()` – генерация через REST API:
  - формирование промпта (2–3 предложения, кратко и информативно);
  - использование конкретной модели и температуры из запроса.
- `generate_summary_with_langchain()` – альтернатива через LangChain.
- `generate_simple_summary()` – первые предложения текста.
- `clean_html()` – очистка HTML (регулярные выражения + декодирование HTML entities).
- `generate_summaries_for_articles()` – пакетная генерация саммари и сохранение в БД.

### `agents/embeddings.py`
- `generate_embedding_with_openai()` – генерация embeddings:
  - учитывает `OPENAI_API_BASE` и выбранную модель;
  - обрабатывает ошибки, в т.ч. 404 (отсутствие поддержки embeddings).
- `clean_text()` – очистка текста от HTML‑тегов и лишних символов.
- `cosine_similarity()` – косинусное сходство двух векторов (NumPy).
- `find_similar_articles()` – поиск похожих статей по embeddings с порогом схожести.
- `semantic_search()` – семантический поиск по текстовому запросу:
  - генерация embedding для запроса;
  - загрузка статей (всех или по `search_history_id`);
  - расчёт и фильтрация по similarity;
  - возвращение списка `(article_data, similarity)`.
- `generate_embeddings_for_articles_by_ids()` – пакетная генерация embeddings по списку ID:
  - загрузка статей в актуальной сессии;
  - генерация вектора только при его отсутствии.
- `generate_embeddings_for_articles()` – обёртка для обратной совместимости.

---

## Семантический поиск и keyword‑matching

### Семантический поиск
1. Пользователь вводит запрос (например, «стоимость визы в Индию»).
2. Система:
   - очищает запрос от стоп‑слов;
   - генерирует embedding запроса;
   - рассчитывает косинусное сходство с embeddings статей.
3. Используется адаптивный порог схожести, зависящий от длины запроса:
   - 1 слово – по умолчанию 0.25;
   - 2 слова – 0.3;
   - 3 слова – 0.35;
   - 4–5 слов – 0.4;
   - 6+ слов – 0.5 (все значения можно поменять через «Системные настройки»).

### Keyword‑matching (дополнительный механизм)
- Поиск точных совпадений слов запроса в:
  - заголовке;
  - содержании;
  - саммари.
- Использование:
  - как буст к результатам, найденным по embeddings (например, +0.1 к `similarity_score`);
  - для включения статей без embeddings, если ≥ заданной доли слов совпадают.
- Итоговый список:
  - объединение результатов семантического поиска и keyword‑matching;
  - сортировка по убыванию итогового score.

Преимущество подхода:
- семантический поиск — основной механизм, устойчивый к синонимам и переформулировкам;
- keyword‑matching используется как дополнительный буст и механизм совместимости.

---

## Обработка ошибок и устойчивость

- Ошибки парсинга RSS:
  - канал пропускается, остальные продолжают обрабатываться.
- Ошибки LLM API:
  - переход на `simple_classification()` (по ключевым словам);
  - логирование подробностей ошибки.
- Ошибки генерации саммари:
  - fallback на `generate_simple_summary()`;
  - остальные статьи продолжают обрабатываться.
- Ошибки embeddings:
  - при 404 или сетевых проблемах семантический поиск отключается для текущей выборки;
  - остальная функциональность продолжает работать.
- Ошибки сохранения в БД:
  - откат транзакции;
  - логирование;
  - система продолжает работу по возможности.

---

## Безопасность

- Очистка HTML‑контента статей (как на этапе подготовки текста для LLM, так и при отображении в UI).
- Санитизация на фронтенде (например, через DOMPurify) для защиты от XSS.
- Валидация входных данных с форм (поля, длины, типы).
- Секретные ключи (API‑ключи, строки подключения к БД) хранятся только в переменных окружения/`.env`.

---

## Производительность

- Пакетная обработка статей (классификация, саммари, embeddings).
- Индексация по `content_hash` для ускорения дедупликации.
- Оптимизированные запросы к БД:
  - выборка только необходимых полей;
  - минимизация количества запросов.
- Фоновая/асинхронная обработка в отдельных потоках для разгрузки основного веб‑процесса.

---

## История запросов

- Каждый запуск поиска создаёт запись в таблице `search_history`:
  - параметры запроса (RSS‑каналы, критерий отбора, модель LLM, температура, порог схожести, endpoint);
  - агрегированная статистика в JSON‑поле `results_data`.
- Все статьи связываются с историей через `search_history_id`.
- При удалении записи истории:
  - каскадно удаляются все связанные статьи.
- UI предоставляет:
  - просмотр параметров и результатов;
  - удаление отдельных запросов;
  - полную очистку базы.

Подробнее о структуре таблиц и полях см. в `docs/Data_Structure.md`.

---

## План развития

### Высокий приоритет
- **Кластеризация новостей по темам**
  - Кластеризация по embeddings (K‑Means, DBSCAN).
  - Автоматическое определение темы кластера.
  - Отображение кластеров в UI.
- **Экспорт данных**
  - Экспорт таблицы статей в CSV/JSON.
  - Генерация PDF‑отчётов.
  - Генерация RSS‑фида отфильтрованных новостей.
- **Аналитика и визуализация**
  - графики динамики релевантных/нерелевантных статей;
  - топ источников по релевантности;
  - анализ тем и временных паттернов.

### Средний приоритет
- Персонализация и рекомендации.
- Кэширование и оптимизация затрат на LLM.
- Улучшения UI/UX (тёмная тема, фильтры, избранное, клавиатурные шорткаты).

### Низкий приоритет / долгосрочно
- Мультиязычность интерфейса и поиска.
- Мониторинг RSS‑источников и уведомления.
- Интеграции и внешние API (Telegram/Discord‑боты, webhooks, email‑дайджесты).
- Планировщик (cron‑like) для автоматического запуска обработки.

### Технические улучшения
- Миграции БД (Alembic), unit/интеграционные тесты, логирование в файлы.
- Docker‑контейнеризация и CI/CD.
- Документация API (Swagger / OpenAPI).
- Поддержка PostgreSQL / MySQL для продакшена.
- Rate limiting и аутентификация при необходимости.

### Улучшения алгоритмов
- Более продвинутые embeddings (multilingual).
- Fine‑tuning моделей на доменных данных.
- Расширение алгоритма дедупликации на основе embeddings.
- Автоматическое определение категорий новостей.
- Sentiment analysis и NER.
- Опциональный словарь синонимов для keyword‑matching (дополнение к embeddings).

