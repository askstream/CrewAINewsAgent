# News Agent

Система для автоматического сбора новостей из RSS‑каналов, дедупликации и интеллектуальной классификации по релевантности с использованием LLM (OpenAI / совместимые API / Ollama).

### Основные возможности
- **Сбор новостей из RSS**: парсинг нескольких RSS/Atom‑фидов, извлечение заголовка, содержимого, даты и ссылки, сохранение в БД.
- **Дедупликация статей**: быстрая проверка по хешу + текстовая схожесть с настраиваемым порогом.
- **Классификация релевантности**: оценка \(0.0–1.0\) через LLM с fallback на keyword‑классификацию.
- **Автоматическое саммари**: краткие 2–3‑предложные саммари для релевантных новостей.
- **Семантический поиск**: embeddings, поиск по смыслу + keyword‑boost.
- **Веб‑интерфейс**: вкладки «Поиск», «История запросов», «Системные настройки» с прогресс‑барами и статистикой.
- **CLI‑режим**: запуск обработки из командной строки на основе настроек из `.env`.

Подробнее об архитектуре и внутренней логике см. в `docs/Architecture.md`, о структуре данных и БД — в `docs/Data_Structure.md`.

---

## Установка

### Требования
- Python 3.8+
- `pip`

### Установка и настройка
1. Клонируйте репозиторий:
   ```bash
   git clone <repo-url>
   cd AINewsAgent
   ```

2. Установите зависимости:
   ```bash
   pip install -r requirements.txt
   ```

3. Создайте файл `.env` на основе примера:
   ```bash
   cp env.example .env
   ```

4. Укажите в `.env` минимум:
   - `OPENAI_API_KEY` – ключ OpenAI или другого провайдера  
     - для Ollama можно указать любое значение (например, `ollama`);
   - `RSS_FEEDS` – список RSS‑каналов через запятую (для CLI‑режима);
   - `SELECTION_CRITERIA` – текстовый критерий отбора новостей (для CLI‑режима).

5. При необходимости настройте дополнительные параметры (см. раздел «Конфигурация» ниже).

---

## Быстрый старт

### Веб‑интерфейс (рекомендуется)
1. Запустите Flask‑приложение:
   ```bash
   python app.py
   ```
2. Откройте в браузере:
   ```text
   http://127.0.0.1:5000
   ```
3. На вкладке «Поиск»:
   - укажите RSS‑каналы (каждый с новой строки);
   - задайте критерий отбора новостей;
   - при необходимости измените модель LLM, температуру и порог дедупликации;
   - нажмите «Начать обработку» и следите за прогрессом.

После завершения вы увидите таблицу уникальных статей с релевантностью, саммари и причинами классификации. История запусков и детальные параметры запросов доступны на вкладке «История запросов».

### CLI‑режим
1. Настройте `.env`, например:
   ```env
   OPENAI_API_KEY=your_api_key
   RSS_FEEDS=https://example.com/feed1.xml,https://example.com/feed2.xml
   SELECTION_CRITERIA=новости о науке и технологиях
   SIMILARITY_THRESHOLD=0.85
   ```
2. Запустите обработку из командной строки:
   ```bash
   python cmd_mode/main.py
   ```

---

## Конфигурация

Основные переменные окружения задаются в `.env`:

- **LLM / API**
  - `OPENAI_API_KEY` – обязательный ключ доступа к LLM‑провайдеру.
  - `OPENAI_API_BASE` – опциональный кастомный endpoint (например, `https://api.proxyapi.ru/openai/v1` или `http://localhost:11434/v1` для Ollama).
  - `LLM_MODEL` – модель для классификации и саммари (по умолчанию `gpt-4o-mini`).
  - `LLM_TEMPERATURE` – температура генерации (по умолчанию `0.7`).

- **Embeddings / семантический поиск**
  - `EMBEDDING_MODEL` – модель embeddings (по умолчанию `text-embedding-3-small`; для Ollama, например, `snowflake-arctic-embed2`).
  - `SIMILARITY_THRESHOLD` – порог схожести для дедупликации (по умолчанию `0.85`).  
    Рекомендуемые диапазоны: `0.8–0.9` — стандарт, `0.9–1.0` — очень строгая проверка.

- **База данных и сервер**
  - `DATABASE_URL` – строка подключения к БД (`sqlite:///data/news_agent.db` по умолчанию).
  - `FLASK_HOST` / `FLASK_PORT` – хост и порт веб‑сервера (по умолчанию `127.0.0.1:5000`).

Дополнительные детальные настройки семантического поиска и keyword‑matching управляются через вкладку «Системные настройки» и описаны в `docs/Architecture.md` и `docs/Data_Structure.md`.

### Использование Ollama
Пример настроек для локальных моделей через Ollama:

```env
OPENAI_API_KEY=ollama
OPENAI_API_BASE=http://localhost:11434/v1
LLM_MODEL=qwen2.5:7b
EMBEDDING_MODEL=snowflake-arctic-embed2
```

Рекомендации по выбору моделей и проверке работы Ollama см. в `docs/ollama_configuration.md`.

---

## Структура проекта

```text
AINewsAgent/
├── app.py               # Flask веб‑приложение и API
├── config.py            # Загрузка конфигурации из .env
├── models.py            # Модели SQLAlchemy
├── requirements.txt     # Зависимости
├── env.example          # Пример файла настроек
├── README.md            # Основная документация
├── docs/                # Дополнительная документация
│   ├── Architecture.md  # Архитектура системы
│   ├── Data_Structure.md# Структура данных и БД
│   └── ollama_configuration.md
├── data/                # База данных (SQLite по умолчанию)
├── cmd_mode/            # CLI‑режим
├── agents/              # Модули обработки (RSS, дедупликация, LLM, embeddings и др.)
├── templates/           # HTML‑шаблоны (основной UI)
└── static/              # CSS / JS статика
```

Подробное описание модулей и их взаимодействия приведено в `docs/Architecture.md`.

---

## Дополнительная документация

- **Архитектура и поток обработки**: `docs/Architecture.md`
- **Структура БД и данные**: `docs/Data_Structure.md`
- **Работа с Ollama и локальными моделями**: `docs/ollama_configuration.md`

При необходимости эти документы можно использовать как основу для Wiki или GitHub Pages.
